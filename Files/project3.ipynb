{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe finder\n",
    "### by Abilash Ramesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import codecs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recipe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    df = pd.read_json(filename)\n",
    "    new = []\n",
    "    for s in df['ingredients']:\n",
    "        s = ' '.join(s)\n",
    "        new.append(s)\n",
    "    df['ing'] = new\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ingredients from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ing(string, df):\n",
    "    user_ing = string\n",
    "    df = df.append({'ing':user_ing}, ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(df, n):\n",
    "    vectorizer = TfidfVectorizer(use_idf = True, smooth_idf=True, stop_words = 'english',max_features = 4000)\n",
    "    ing_vect = vectorizer.fit_transform((df['ing'].values))\n",
    "    vec = ing_vect.todense()\n",
    "    X_train_df = vec[:-1]\n",
    "    y_train_df = df['cuisine'][:-1]\n",
    "    X_test_df = vec[-1]\n",
    "    n = n\n",
    "    model = KNeighborsClassifier(n_neighbors = n, weights='uniform', algorithm='auto', metric='minkowski')\n",
    "    preds = model.fit(X_train_df,y_train_df)\n",
    "    return X_test_df, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain results for the given set of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(test, model, n):\n",
    "    \n",
    "    predicted_class = model.classes_\n",
    "    predicted_single_cuisine = model.predict(test)\n",
    "    predicted_cuisine = model.predict_proba(test)[0]\n",
    "    match_perc,match_id = model.kneighbors(test)\n",
    "    pos = np.where(predicted_class == predicted_single_cuisine)\n",
    "    print (\"The model predicts that the ingredients resembles %s (%f resemblence)\\n\" %(predicted_single_cuisine[0], predicted_cuisine[pos]*100))\n",
    "    for i in range(0, len(match_id[0][:n])):\n",
    "        print ('Recipe No: %d (%f probable match)'%(match_id[0][i], match_perc[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The recipes and the closest type of cuisine is displayed\n",
    "You will need to run the below code every time you want to find the cuisine/recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data('/Users/anrame/Documents/Spring 2020/Text Analytics/Project 3/yummly.json')\n",
    "df = get_user_ing('thyme, basil', df)\n",
    "test, mod = train_data(df, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts that the ingredients resembles italian (63.636364 resemblence)\n",
      "\n",
      "Recipe No: 38052 (0.995421 probable match)\n",
      "Recipe No: 33387 (1.014186 probable match)\n",
      "Recipe No: 16446 (1.042872 probable match)\n",
      "Recipe No: 21589 (1.074481 probable match)\n",
      "Recipe No: 24719 (1.077459 probable match)\n"
     ]
    }
   ],
   "source": [
    "get_results(test, mod, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results2(test, model):\n",
    "    \n",
    "    predicted_class = model.classes_\n",
    "    predicted_single_cuisine = model.predict(test)\n",
    "    predicted_cuisine = model.predict_proba(test)[0]\n",
    "    #match_perc,match_id = model.kneighbors(test)\n",
    "    pos = np.where(predicted_class == predicted_single_cuisine)\n",
    "    print (\"The model predicts that the ingredients resembles %s (%f resemblence)\\n\" %(predicted_single_cuisine[0], predicted_cuisine[pos]*100))\n",
    "    #for i in range(len(match_id[0])):\n",
    "     #   print ('Recipe No: %d (%f probable match)'%(match_id[0][i], match_perc[0][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data2(df):\n",
    "    vectorizer = TfidfVectorizer(use_idf = True, smooth_idf=True, stop_words = 'english',max_features = 4000)\n",
    "    ing_vect = vectorizer.fit_transform((df['ing'].values))\n",
    "    vec = ing_vect.todense()\n",
    "    X_train_df = vec[:-1]\n",
    "    y_train_df = df['cuisine'][:-1]\n",
    "    X_test_df = vec[-1]\n",
    "    n = 11\n",
    "    tr2 = MLPClassifier(hidden_layer_sizes=(5, ),activation='relu', solver='adam', alpha=0.001)\n",
    "    preds = tr2.fit(X_train_df,y_train_df)\n",
    "    return X_test_df, tr2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anrame/anaconda2/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "test2, mod2 = train_data2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts that the ingredients resembles southern_us (78.502856 resemblence)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_results2(test2, mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
